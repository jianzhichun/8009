{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jianzhichun/8009/blob/main/group.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "Kc4kwXDZViGT",
        "outputId": "f1ee2bf6-2b62-4222-da6b-c687dffbc8e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.7/dist-packages (2.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.63.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.21.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.3.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "# !pip uninstall torch-scatter\n",
        "# !pip uninstall torch-sparse\n",
        "!pip install torch-geometric\n",
        "\n",
        "#if you are doing it on your local machine, pls figure out your pytorch version and the cuda version and modify the following code accordingly.\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu113.html"
      ],
      "id": "Kc4kwXDZViGT"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "J831nLYwViGU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "import pandas as pd\n",
        "from torch_geometric.data import InMemoryDataset, Data, download_url, extract_zip\n",
        "from torch_geometric.utils.convert import to_networkx\n",
        "import networkx as nx\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt"
      ],
      "id": "J831nLYwViGU"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-yaHJk1ViGU"
      },
      "source": [
        "To create the dataset we need to convert the raw information into a ```Data``` object (a graph) in PyG.\n",
        "\n",
        "The first step is to load the csv files, this can be done manually or using some data library as Pandas:"
      ],
      "id": "P-yaHJk1ViGU"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4x0tTViViGY"
      },
      "source": [
        "### Open Graph Benchmark datasets"
      ],
      "id": "p4x0tTViViGY"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmLTZEZ4ViGY"
      },
      "source": [
        "Open Graph Benchmark is available as a python library, to install it just run\n",
        "\n",
        "```pip install ogb```"
      ],
      "id": "DmLTZEZ4ViGY"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqYtXEmjViGY"
      },
      "source": [
        "OGB allows to load a dataset in three ways: for PyG applications, for DGL (Deep Graph Library, another widely used tool for GNNs in python) and in an 'agnostic' manner. There is a naming convention to load a dataset, depending on the task an the dataset name:\n",
        "\n",
        "    ogbn-[name]: for node tasks\n",
        "    ogbg-[name]: for graph tasks\n",
        "    ogbl-[name]: for link tasks"
      ],
      "id": "PqYtXEmjViGY"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ogb"
      ],
      "metadata": {
        "id": "mP09G9dIWuWK",
        "outputId": "a0055758-bcac-4817-f3ee-42b1a58da2d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "mP09G9dIWuWK",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ogb\n",
            "  Downloading ogb-1.3.3-py3-none-any.whl (78 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▏                           | 10 kB 22.2 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 20 kB 28.7 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 30 kB 23.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 40 kB 10.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 51 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 61 kB 14.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 71 kB 10.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 78 kB 3.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.10.0+cu111)\n",
            "Collecting outdated>=0.2.0\n",
            "  Downloading outdated-0.2.1-py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.3.5)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.24.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.15.0)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (4.63.0)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.21.5)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.0.2)\n",
            "Collecting littleutils\n",
            "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from outdated>=0.2.0->ogb) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->ogb) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->ogb) (2018.9)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->ogb) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->ogb) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->ogb) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->ogb) (3.10.0.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->ogb) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->ogb) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->ogb) (2.10)\n",
            "Building wheels for collected packages: littleutils\n",
            "  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7048 sha256=a0b209b7a6648736c3c933a2103071f34296c3ff20e44357f1f64eb04a8d8d94\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/64/cd/32819b511a488e4993f2fab909a95330289c3f4e0f6ef4676d\n",
            "Successfully built littleutils\n",
            "Installing collected packages: littleutils, outdated, ogb\n",
            "Successfully installed littleutils-0.2.2 ogb-1.3.3 outdated-0.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Wyb9bVD-ViGY"
      },
      "outputs": [],
      "source": [
        "from ogb.nodeproppred import PygNodePropPredDataset\n",
        "#from ogb.graphproppred import PygGraphPropPredDataset\n",
        "#from ogb.linkproppred import PygLinkPropPredDataset"
      ],
      "id": "Wyb9bVD-ViGY"
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "l1zadVohViGY"
      },
      "outputs": [],
      "source": [
        "dataset_name = 'ogbn-arxiv'\n",
        "dataset = PygNodePropPredDataset(name = dataset_name, root='data', transform=T.ToSparseTensor()) \n",
        "\n",
        "split_idx = dataset.get_idx_split()\n",
        "train_idx, valid_idx, test_idx = split_idx[\"train\"], split_idx[\"valid\"], split_idx[\"test\"]\n",
        "graph = dataset[0] "
      ],
      "id": "l1zadVohViGY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### You have to write a short proposal for me to review."
      ],
      "metadata": {
        "id": "LFz1-mfzcw9r"
      },
      "id": "LFz1-mfzcw9r"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, I will try to use Graph Neural Networks to predict a collection of papers from arXiv. We will build our first graph neural network using PyTorch Geometric and apply it to node attribute prediction (node classification). And We will build a graph neural network using the GCN operator."
      ],
      "metadata": {
        "id": "lq7xWYoQeeEn"
      },
      "id": "lq7xWYoQeeEn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Describe the problem and the dataset clearly."
      ],
      "metadata": {
        "id": "FDn_SH5Gc48i"
      },
      "id": "FDn_SH5Gc48i"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What’s the input, what’s the output?"
      ],
      "metadata": {
        "id": "z_pyb3JldFBk"
      },
      "id": "z_pyb3JldFBk"
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Input: the graph data with {graph.num_features} features')\n",
        "print(f'Output: the accuracy of our prediction model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0BuhoHedaLS",
        "outputId": "0484c26e-8f54-46c8-cb16-7bd0afcd5edb"
      },
      "id": "x0BuhoHedaLS",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: the graph data with 128 features\n",
            "Output: the accuracy of our prediction model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Why is the problem important?"
      ],
      "metadata": {
        "id": "S71lrYyGdNA4"
      },
      "id": "S71lrYyGdNA4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding an accurate model can help us classify papers and predict the properties of papers."
      ],
      "metadata": {
        "id": "cQNrCJR_hWIn"
      },
      "id": "cQNrCJR_hWIn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What’s the most popular baseline method?"
      ],
      "metadata": {
        "id": "G9kR7yLRdPtf"
      },
      "id": "G9kR7yLRdPtf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "GCN, Node2Vec, MLP..."
      ],
      "metadata": {
        "id": "VZoOWF8iiBQu"
      },
      "id": "VZoOWF8iiBQu"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What’s the evaluation metric?"
      ],
      "metadata": {
        "id": "Nb4Pyk1adS-0"
      },
      "id": "Nb4Pyk1adS-0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The standardized evaluation protocol from ogb.\n",
        "* The accuracy, precision, recall and F1-score"
      ],
      "metadata": {
        "id": "P9Y-ldY0iQKj"
      },
      "id": "P9Y-ldY0iQKj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction Model"
      ],
      "metadata": {
        "id": "JSqWrgtBj521"
      },
      "id": "JSqWrgtBj521"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GCN"
      ],
      "metadata": {
        "id": "sOvWCSxCkAZ9"
      },
      "id": "sOvWCSxCkAZ9"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers,\n",
        "                 dropout, return_embeds=False):\n",
        "        # TODO: Implement this function that initializes self.convs, \n",
        "        # self.bns, and self.softmax.\n",
        "\n",
        "        super(GCN, self).__init__()\n",
        "\n",
        "        # A list of GCNConv layers\n",
        "        self.convs = torch.nn.ModuleList(\n",
        "            [GCNConv(in_channels=input_dim, out_channels=hidden_dim)] +\n",
        "            [GCNConv(in_channels=hidden_dim, out_channels=hidden_dim)                             \n",
        "                for i in range(num_layers-2)] + \n",
        "            [GCNConv(in_channels=hidden_dim, out_channels=output_dim)]    \n",
        "        )\n",
        "\n",
        "        # A list of 1D batch normalization layers\n",
        "        self.bns = torch.nn.ModuleList([\n",
        "            torch.nn.BatchNorm1d(num_features=hidden_dim) \n",
        "                for i in range(num_layers-1)\n",
        "        ])\n",
        "        \n",
        "\n",
        "        # The log softmax layer\n",
        "        self.softmax = torch.nn.LogSoftmax()\n",
        "\n",
        "        ############# Your code here ############\n",
        "        ## Note:\n",
        "        ## 1. You should use torch.nn.ModuleList for self.convs and self.bns\n",
        "        ## 2. self.convs has num_layers GCNConv layers\n",
        "        ## 3. self.bns has num_layers - 1 BatchNorm1d layers\n",
        "        ## 4. You should use torch.nn.LogSoftmax for self.softmax\n",
        "        ## 5. The parameters you can set for GCNConv include 'in_channels' and \n",
        "        ## 'out_channels'. More information please refer to the documentation:\n",
        "        ## https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GCNConv\n",
        "        ## 6. The only parameter you need to set for BatchNorm1d is 'num_features'\n",
        "        ## More information please refer to the documentation: \n",
        "        ## https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html\n",
        "        ## (~10 lines of code)\n",
        "\n",
        "        #########################################\n",
        "\n",
        "        # Probability of an element to be zeroed\n",
        "        self.dropout = dropout\n",
        "\n",
        "        # Skip classification layer and return node embeddings\n",
        "        self.return_embeds = return_embeds\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "        for bn in self.bns:\n",
        "            bn.reset_parameters()\n",
        "\n",
        "    def forward(self, x, adj_t):\n",
        "        # TODO: Implement this function that takes the feature tensor x,\n",
        "        # edge_index tensor adj_t and returns the output tensor as\n",
        "        # shown in the figure.\n",
        "        for conv, bn in zip(self.convs[:-1], self.bns):\n",
        "            x1 = F.relu(bn(conv(x, adj_t)))\n",
        "            if self.training:\n",
        "                x1 = F.dropout(x1, p=self.dropout)\n",
        "            x = x1\n",
        "        x = self.convs[-1](x, adj_t)\n",
        "        out = x if self.return_embeds else self.softmax(x)\n",
        "\n",
        "        ############# Your code here ############\n",
        "        ## Note:\n",
        "        ## 1. Construct the network as showing in the figure\n",
        "        ## 2. torch.nn.functional.relu and torch.nn.functional.dropout are useful\n",
        "        ## More information please refer to the documentation:\n",
        "        ## https://pytorch.org/docs/stable/nn.functional.html\n",
        "        ## 3. Don't forget to set F.dropout training to self.training\n",
        "        ## 4. If return_embeds is True, then skip the last softmax layer\n",
        "        ## (~7 lines of code)\n",
        "\n",
        "        #########################################\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "2VZVtcLJjjoJ"
      },
      "id": "2VZVtcLJjjoJ",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GGNN"
      ],
      "metadata": {
        "id": "vi0sL_TukVKD"
      },
      "id": "vi0sL_TukVKD"
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "metadata": {
        "id": "9Gvum4OXj_LN"
      },
      "id": "9Gvum4OXj_LN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train & Evaluation"
      ],
      "metadata": {
        "id": "PdaRzKmakY5r"
      },
      "id": "PdaRzKmakY5r"
    },
    {
      "cell_type": "code",
      "source": [
        "from ogb.nodeproppred import Evaluator\n",
        "def train(model, data, train_idx, optimizer, loss_fn):\n",
        "    # TODO: Implement this function that trains the model by \n",
        "    # using the given optimizer and loss_fn.\n",
        "    model.train()\n",
        "    loss = 0\n",
        "\n",
        "    ############# Your code here ############\n",
        "    ## Note:\n",
        "    ## 1. Zero grad the optimizer\n",
        "    ## 2. Feed the data into the model\n",
        "    ## 3. Slicing the model output and label by train_idx\n",
        "    ## 4. Feed the sliced output and label to loss_fn\n",
        "    ## (~4 lines of code)\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.adj_t)\n",
        "    loss = loss_fn(out[train_idx], data.y[train_idx].reshape(-1))\n",
        "\n",
        "    #########################################\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item()\n",
        "@torch.no_grad()\n",
        "def test(model, data, split_idx, evaluator):\n",
        "    # TODO: Implement this function that tests the model by \n",
        "    # using the given split_idx and evaluator.\n",
        "    model.eval()\n",
        "\n",
        "    # The output of model on all data\n",
        "    out = None\n",
        "\n",
        "    ############# Your code here ############\n",
        "    ## (~1 line of code)\n",
        "    ## Note:\n",
        "    ## 1. No index slicing here\n",
        "    out = model(data.x, data.adj_t)\n",
        "    #########################################\n",
        "\n",
        "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
        "\n",
        "    train_acc = evaluator.eval({\n",
        "        'y_true': data.y[split_idx['train']],\n",
        "        'y_pred': y_pred[split_idx['train']],\n",
        "    })['acc']\n",
        "    valid_acc = evaluator.eval({\n",
        "        'y_true': data.y[split_idx['valid']],\n",
        "        'y_pred': y_pred[split_idx['valid']],\n",
        "    })['acc']\n",
        "    test_acc = evaluator.eval({\n",
        "        'y_true': data.y[split_idx['test']],\n",
        "        'y_pred': y_pred[split_idx['test']],\n",
        "    })['acc']\n",
        "\n",
        "    return train_acc, valid_acc, test_acc"
      ],
      "metadata": {
        "id": "Jno4FZw8kdfr"
      },
      "id": "Jno4FZw8kdfr",
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Apply & Compare"
      ],
      "metadata": {
        "id": "2ziyqvjCkvXY"
      },
      "id": "2ziyqvjCkvXY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GCN"
      ],
      "metadata": {
        "id": "uUvA3wz3k8PH"
      },
      "id": "uUvA3wz3k8PH"
    },
    {
      "cell_type": "code",
      "source": [
        "model = GCN(graph.num_features, 256, dataset.num_classes, 3, 0.5).to('cpu')\n",
        "evaluator = Evaluator(name='ogbn-arxiv')\n",
        "import copy\n",
        "\n",
        "# reset the parameters to initial random value\n",
        "model.reset_parameters()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "loss_fn = F.nll_loss\n",
        "\n",
        "best_model = None\n",
        "best_valid_acc = 0\n",
        "\n",
        "# TODO\n",
        "epochs = 1\n",
        "for epoch in range(1, 1 + epochs):\n",
        "  loss = train(model, graph, train_idx, optimizer, loss_fn)\n",
        "  result = test(model, graph, split_idx, evaluator)\n",
        "  train_acc, valid_acc, test_acc = result\n",
        "  if valid_acc > best_valid_acc:\n",
        "    best_valid_acc = valid_acc\n",
        "    best_model = copy.deepcopy(model)\n",
        "best_result = test(best_model, graph, split_idx, evaluator)\n",
        "train_acc, valid_acc, test_acc = best_result\n",
        "print(f'Best model: '\n",
        "  f'Train: {100 * train_acc:.2f}%, '\n",
        "  f'Valid: {100 * valid_acc:.2f}% '\n",
        "  f'Test: {100 * test_acc:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQ0Gm1yrk43Y",
        "outputId": "38da1805-6878-4018-82cb-20066ef1a243"
      },
      "id": "wQ0Gm1yrk43Y",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:69: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model: Train: 1.59%, Valid: 1.64% Test: 1.41%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "load_data_from_ogbn_arxiv.ipynb",
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}