{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "<a href=\"https://colab.research.google.com/github/jianzhichun/8009/blob/main/group.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text",
    "cell_id": "ac374e7f-a23a-4f09-981a-66935ea4c86a",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 90
   }
  },
  {
   "cell_type": "code",
   "source": "import torch\nprint(torch.__version__)",
   "metadata": {
    "cell_id": "dcfb64dbc00b4a4893720e17454baed6",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "bd665810",
    "execution_start": 1649551144161,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 129.859375
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "1.11.0+cu102\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Kc4kwXDZViGT",
    "outputId": "f1ee2bf6-2b62-4222-da6b-c687dffbc8e2",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "cell_id": "00001-3f3ede1c-d802-4cbb-a78d-f5ece0459f55",
    "owner_user_id": "cab3b104-0ce6-4e64-b13a-0c3b6085828b",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 595.421875
   },
   "source": "# !pip uninstall torch-scatter\n# !pip uninstall torch-sparse\n!pip install -q torch-geometric -f https://data.pyg.org/whl/torch-1.11.0+cu102.html\n\n#if you are doing it on your local machine, pls figure out your pytorch version and the cuda version and modify the following code accordingly.\n!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-1.11.0+cu102.html\n!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-1.11.0+cu102.html\n!pip install -q networkx",
   "execution_count": 38,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.7/dist-packages (2.0.4)\nRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\nRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.63.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.21.5)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.7)\nRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.3.5)\nRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\nRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\nRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.10.8)\nRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\nRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "J831nLYwViGU",
    "cell_id": "00002-e892519d-e799-4a73-bce1-da94a6f9e4d3",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 192
   },
   "source": "import torch\nimport os\nimport pandas as pd\nfrom torch_geometric.data import InMemoryDataset, Data, download_url, extract_zip\nfrom torch_geometric.utils.convert import to_networkx\nimport networkx as nx\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt",
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "To create the dataset we need to convert the raw information into a ```Data``` object (a graph) in PyG.\n\nThe first step is to load the csv files, this can be done manually or using some data library as Pandas:",
   "metadata": {
    "id": "P-yaHJk1ViGU",
    "cell_id": "00003-80ce4e77-67cb-423f-8bbe-55d14f9e633e",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 88.78125
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Open Graph Benchmark datasets",
   "metadata": {
    "id": "p4x0tTViViGY",
    "cell_id": "00004-8556d921-2c40-44f4-9cfc-926f16be2aad",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 62
   }
  },
  {
   "cell_type": "markdown",
   "source": "Open Graph Benchmark is available as a python library, to install it just run\n\n```pip install ogb```",
   "metadata": {
    "id": "DmLTZEZ4ViGY",
    "cell_id": "00005-5d693ee2-fe1e-4d15-81f9-3842f6294c12",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 88.78125
   }
  },
  {
   "cell_type": "markdown",
   "source": "OGB allows to load a dataset in three ways: for PyG applications, for DGL (Deep Graph Library, another widely used tool for GNNs in python) and in an 'agnostic' manner. There is a naming convention to load a dataset, depending on the task an the dataset name:\n\n    ogbn-[name]: for node tasks\n    ogbg-[name]: for graph tasks\n    ogbl-[name]: for link tasks",
   "metadata": {
    "id": "PqYtXEmjViGY",
    "cell_id": "00006-9766d515-6983-45be-a5ab-668b8dd20387",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 171.15625
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mP09G9dIWuWK",
    "outputId": "a0055758-bcac-4817-f3ee-42b1a58da2d6",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "cell_id": "00007-febdbf8b-08d0-421b-ba80-006865e33bea",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 746
   },
   "source": "!pip install ogb",
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Collecting ogb\n  Downloading ogb-1.3.3-py3-none-any.whl (78 kB)\n\u001b[?25l\r\u001b[K     |████▏                           | 10 kB 22.2 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 20 kB 28.7 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 30 kB 23.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 40 kB 10.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 51 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 61 kB 14.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 71 kB 10.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 78 kB 3.9 MB/s \n\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.10.0+cu111)\nCollecting outdated>=0.2.0\n  Downloading outdated-0.2.1-py3-none-any.whl (7.5 kB)\nRequirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.3.5)\nRequirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.24.3)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.15.0)\nRequirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (4.63.0)\nRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.21.5)\nRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.0.2)\nCollecting littleutils\n  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\nRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from outdated>=0.2.0->ogb) (2.23.0)\nRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->ogb) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->ogb) (2018.9)\nRequirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->ogb) (1.4.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->ogb) (3.1.0)\nRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->ogb) (1.1.0)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->ogb) (3.10.0.2)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->ogb) (2021.10.8)\nRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->ogb) (3.0.4)\nRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->ogb) (2.10)\nBuilding wheels for collected packages: littleutils\n  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7048 sha256=a0b209b7a6648736c3c933a2103071f34296c3ff20e44357f1f64eb04a8d8d94\n  Stored in directory: /root/.cache/pip/wheels/d6/64/cd/32819b511a488e4993f2fab909a95330289c3f4e0f6ef4676d\nSuccessfully built littleutils\nInstalling collected packages: littleutils, outdated, ogb\nSuccessfully installed littleutils-0.2.2 ogb-1.3.3 outdated-0.2.1\n"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Wyb9bVD-ViGY",
    "cell_id": "00008-e36b477e-fb02-4965-9296-72b756aa4ddc",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 102
   },
   "source": "from ogb.nodeproppred import PygNodePropPredDataset\n#from ogb.graphproppred import PygGraphPropPredDataset\n#from ogb.linkproppred import PygLinkPropPredDataset",
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "l1zadVohViGY",
    "cell_id": "00009-6e8ee457-dae9-4b86-b427-111af038ca39",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 156
   },
   "source": "dataset_name = 'ogbn-arxiv'\ndataset = PygNodePropPredDataset(name = dataset_name, root='data', transform=T.ToSparseTensor()) \n\nsplit_idx = dataset.get_idx_split()\ntrain_idx, valid_idx, test_idx = split_idx[\"train\"], split_idx[\"valid\"], split_idx[\"test\"]\ngraph = dataset[0] ",
   "execution_count": 50,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### You have to write a short proposal for me to review.",
   "metadata": {
    "id": "LFz1-mfzcw9r",
    "cell_id": "00010-6ce9d0dc-2043-4cd2-8fe9-a8f5911ce706",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 62
   }
  },
  {
   "cell_type": "markdown",
   "source": "In this project, I will try to use Graph Neural Networks to predict a collection of papers from arXiv. We will build our first graph neural network using PyTorch Geometric and apply it to node attribute prediction (node classification). And We will build a graph neural network using the GCN operator.",
   "metadata": {
    "id": "lq7xWYoQeeEn",
    "cell_id": "00011-95a86b9d-1bb9-4f4c-8576-cf616795f6f6",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 74.78125
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Describe the problem and the dataset clearly.",
   "metadata": {
    "id": "FDn_SH5Gc48i",
    "cell_id": "00012-1f6894e2-2ccd-428b-bf42-ce6378735ca7",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 62
   }
  },
  {
   "cell_type": "markdown",
   "source": "#### What’s the input, what’s the output?",
   "metadata": {
    "id": "z_pyb3JldFBk",
    "cell_id": "00013-c3afe2fb-9d2a-4dbc-8f85-13717376263d",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 54
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x0BuhoHedaLS",
    "outputId": "0484c26e-8f54-46c8-cb16-7bd0afcd5edb",
    "cell_id": "00014-7dea8c2c-1908-4be4-a2e9-11525f7826f3",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 149.71875
   },
   "source": "print(f'Input: the graph data with {graph.num_features} features')\nprint(f'Output: the accuracy of our prediction model')",
   "execution_count": 34,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Input: the graph data with 128 features\nOutput: the accuracy of our prediction model\n"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "#### Why is the problem important?",
   "metadata": {
    "id": "S71lrYyGdNA4",
    "cell_id": "00015-f2e65b2c-1c4d-45a9-bc31-6dec5ee44f23",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 54
   }
  },
  {
   "cell_type": "markdown",
   "source": "Finding an accurate model can help us classify papers and predict the properties of papers.",
   "metadata": {
    "id": "cQNrCJR_hWIn",
    "cell_id": "00016-5b68f283-ed4c-4dff-8b0f-a57fa2087b9d",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 52.390625
   }
  },
  {
   "cell_type": "markdown",
   "source": "#### What’s the most popular baseline method?",
   "metadata": {
    "id": "G9kR7yLRdPtf",
    "cell_id": "00017-fcf00c31-cd60-4358-96e0-dc7da982249d",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 54
   }
  },
  {
   "cell_type": "markdown",
   "source": "GCN, Node2Vec, MLP...",
   "metadata": {
    "id": "VZoOWF8iiBQu",
    "cell_id": "00018-96a9c904-e4c7-480a-97dd-5a4563e3068f",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 52.390625
   }
  },
  {
   "cell_type": "markdown",
   "source": "#### What’s the evaluation metric?",
   "metadata": {
    "id": "Nb4Pyk1adS-0",
    "cell_id": "00019-190d6ec6-04fb-41fe-89c0-2927d2e18ea9",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 54
   }
  },
  {
   "cell_type": "markdown",
   "source": "* The standardized evaluation protocol from ogb.\n* The accuracy, precision, recall and F1-score",
   "metadata": {
    "id": "P9Y-ldY0iQKj",
    "cell_id": "00020-727169ea-169a-4f34-ad1e-966ae6e3620f",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 94.78125
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Prediction Model",
   "metadata": {
    "id": "JSqWrgtBj521",
    "cell_id": "00021-3d0309f3-43bf-4045-aecd-1826962250f9",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 62
   }
  },
  {
   "cell_type": "markdown",
   "source": "#### GCN",
   "metadata": {
    "id": "sOvWCSxCkAZ9",
    "cell_id": "00022-2fdd9047-7d1e-4141-b016-23389ded68a5",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 54
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2VZVtcLJjjoJ",
    "cell_id": "00023-b6cc751d-c104-4858-8f16-8684b8566af8",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 1542
   },
   "source": "import torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv\n\nimport torch_geometric.transforms as T\nclass GCN(torch.nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim, num_layers,\n                 dropout, return_embeds=False):\n        # TODO: Implement this function that initializes self.convs, \n        # self.bns, and self.softmax.\n\n        super(GCN, self).__init__()\n\n        # A list of GCNConv layers\n        self.convs = torch.nn.ModuleList(\n            [GCNConv(in_channels=input_dim, out_channels=hidden_dim)] +\n            [GCNConv(in_channels=hidden_dim, out_channels=hidden_dim)                             \n                for i in range(num_layers-2)] + \n            [GCNConv(in_channels=hidden_dim, out_channels=output_dim)]    \n        )\n\n        # A list of 1D batch normalization layers\n        self.bns = torch.nn.ModuleList([\n            torch.nn.BatchNorm1d(num_features=hidden_dim) \n                for i in range(num_layers-1)\n        ])\n        \n\n        # The log softmax layer\n        self.softmax = torch.nn.LogSoftmax()\n\n        ############# Your code here ############\n        ## Note:\n        ## 1. You should use torch.nn.ModuleList for self.convs and self.bns\n        ## 2. self.convs has num_layers GCNConv layers\n        ## 3. self.bns has num_layers - 1 BatchNorm1d layers\n        ## 4. You should use torch.nn.LogSoftmax for self.softmax\n        ## 5. The parameters you can set for GCNConv include 'in_channels' and \n        ## 'out_channels'. More information please refer to the documentation:\n        ## https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GCNConv\n        ## 6. The only parameter you need to set for BatchNorm1d is 'num_features'\n        ## More information please refer to the documentation: \n        ## https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html\n        ## (~10 lines of code)\n\n        #########################################\n\n        # Probability of an element to be zeroed\n        self.dropout = dropout\n\n        # Skip classification layer and return node embeddings\n        self.return_embeds = return_embeds\n\n    def reset_parameters(self):\n        for conv in self.convs:\n            conv.reset_parameters()\n        for bn in self.bns:\n            bn.reset_parameters()\n\n    def forward(self, x, adj_t):\n        # TODO: Implement this function that takes the feature tensor x,\n        # edge_index tensor adj_t and returns the output tensor as\n        # shown in the figure.\n        for conv, bn in zip(self.convs[:-1], self.bns):\n            x1 = F.relu(bn(conv(x, adj_t)))\n            if self.training:\n                x1 = F.dropout(x1, p=self.dropout)\n            x = x1\n        x = self.convs[-1](x, adj_t)\n        out = x if self.return_embeds else self.softmax(x)\n\n        ############# Your code here ############\n        ## Note:\n        ## 1. Construct the network as showing in the figure\n        ## 2. torch.nn.functional.relu and torch.nn.functional.dropout are useful\n        ## More information please refer to the documentation:\n        ## https://pytorch.org/docs/stable/nn.functional.html\n        ## 3. Don't forget to set F.dropout training to self.training\n        ## 4. If return_embeds is True, then skip the last softmax layer\n        ## (~7 lines of code)\n\n        #########################################\n\n        return out",
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "#### GGNN",
   "metadata": {
    "id": "vi0sL_TukVKD",
    "cell_id": "00024-8e5a118f-c735-4819-9d78-8b527e5ae3d6",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 54
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9Gvum4OXj_LN",
    "cell_id": "00025-59f0f9d2-628c-4308-9fe1-134c1f2ea409",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 66
   },
   "source": "# TODO",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Train & Evaluation",
   "metadata": {
    "id": "PdaRzKmakY5r",
    "cell_id": "00026-b81350e0-6429-4ee3-9370-77b83df6394d",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 62
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Jno4FZw8kdfr",
    "cell_id": "00027-4463038d-2c00-41cf-a7e9-3d956615b5e9",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 1056
   },
   "source": "from ogb.nodeproppred import Evaluator\ndef train(model, data, train_idx, optimizer, loss_fn):\n    # TODO: Implement this function that trains the model by \n    # using the given optimizer and loss_fn.\n    model.train()\n    loss = 0\n\n    ############# Your code here ############\n    ## Note:\n    ## 1. Zero grad the optimizer\n    ## 2. Feed the data into the model\n    ## 3. Slicing the model output and label by train_idx\n    ## 4. Feed the sliced output and label to loss_fn\n    ## (~4 lines of code)\n    optimizer.zero_grad()\n    out = model(data.x, data.adj_t)\n    loss = loss_fn(out[train_idx], data.y[train_idx].reshape(-1))\n\n    #########################################\n\n    loss.backward()\n    optimizer.step()\n\n    return loss.item()\n@torch.no_grad()\ndef test(model, data, split_idx, evaluator):\n    # TODO: Implement this function that tests the model by \n    # using the given split_idx and evaluator.\n    model.eval()\n\n    # The output of model on all data\n    out = None\n\n    ############# Your code here ############\n    ## (~1 line of code)\n    ## Note:\n    ## 1. No index slicing here\n    out = model(data.x, data.adj_t)\n    #########################################\n\n    y_pred = out.argmax(dim=-1, keepdim=True)\n\n    train_acc = evaluator.eval({\n        'y_true': data.y[split_idx['train']],\n        'y_pred': y_pred[split_idx['train']],\n    })['acc']\n    valid_acc = evaluator.eval({\n        'y_true': data.y[split_idx['valid']],\n        'y_pred': y_pred[split_idx['valid']],\n    })['acc']\n    test_acc = evaluator.eval({\n        'y_true': data.y[split_idx['test']],\n        'y_pred': y_pred[split_idx['test']],\n    })['acc']\n\n    return train_acc, valid_acc, test_acc",
   "execution_count": 51,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Apply & Compare",
   "metadata": {
    "id": "2ziyqvjCkvXY",
    "cell_id": "00028-e3689cbc-f4e0-4f18-b70b-93183fbb5026",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 62
   }
  },
  {
   "cell_type": "markdown",
   "source": "#### GCN",
   "metadata": {
    "id": "uUvA3wz3k8PH",
    "cell_id": "00029-b6ba895a-d22b-49a2-81d7-3c6ae85a9585",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 54
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wQ0Gm1yrk43Y",
    "outputId": "38da1805-6878-4018-82cb-20066ef1a243",
    "cell_id": "00030-5b2660d0-c39e-4882-bb16-bf14179b6aaf",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 648.390625
   },
   "source": "model = GCN(graph.num_features, 256, dataset.num_classes, 3, 0.5).to('cpu')\nevaluator = Evaluator(name='ogbn-arxiv')\nimport copy\n\n# reset the parameters to initial random value\nmodel.reset_parameters()\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\nloss_fn = F.nll_loss\n\nbest_model = None\nbest_valid_acc = 0\n\n# TODO\nepochs = 100\nfor epoch in range(1, 1 + epochs):\n  loss = train(model, graph, train_idx, optimizer, loss_fn)\n  result = test(model, graph, split_idx, evaluator)\n  train_acc, valid_acc, test_acc = result\n  if valid_acc > best_valid_acc:\n    best_valid_acc = valid_acc\n    best_model = copy.deepcopy(model)\nbest_result = test(best_model, graph, split_idx, evaluator)\ntrain_acc, valid_acc, test_acc = best_result\nprint(f'Best model: '\n  f'Train: {100 * train_acc:.2f}%, '\n  f'Valid: {100 * valid_acc:.2f}% '\n  f'Test: {100 * test_acc:.2f}%')",
   "execution_count": 52,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:69: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Best model: Train: 1.59%, Valid: 1.64% Test: 1.41%\n"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=ff505976-6683-4cd6-82f7-fd1506e405f3' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiPz4KPHN2ZyB3aWR0aD0iODBweCIgaGVpZ2h0PSI4MHB4IiB2aWV3Qm94PSIwIDAgODAgODAiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayI+CiAgICA8IS0tIEdlbmVyYXRvcjogU2tldGNoIDU0LjEgKDc2NDkwKSAtIGh0dHBzOi8vc2tldGNoYXBwLmNvbSAtLT4KICAgIDx0aXRsZT5Hcm91cCAzPC90aXRsZT4KICAgIDxkZXNjPkNyZWF0ZWQgd2l0aCBTa2V0Y2guPC9kZXNjPgogICAgPGcgaWQ9IkxhbmRpbmciIHN0cm9rZT0ibm9uZSIgc3Ryb2tlLXdpZHRoPSIxIiBmaWxsPSJub25lIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiPgogICAgICAgIDxnIGlkPSJBcnRib2FyZCIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoLTEyMzUuMDAwMDAwLCAtNzkuMDAwMDAwKSI+CiAgICAgICAgICAgIDxnIGlkPSJHcm91cC0zIiB0cmFuc2Zvcm09InRyYW5zbGF0ZSgxMjM1LjAwMDAwMCwgNzkuMDAwMDAwKSI+CiAgICAgICAgICAgICAgICA8cG9seWdvbiBpZD0iUGF0aC0yMCIgZmlsbD0iIzAyNjVCNCIgcG9pbnRzPSIyLjM3NjIzNzYyIDgwIDM4LjA0NzY2NjcgODAgNTcuODIxNzgyMiA3My44MDU3NTkyIDU3LjgyMTc4MjIgMzIuNzU5MjczOSAzOS4xNDAyMjc4IDMxLjY4MzE2ODMiPjwvcG9seWdvbj4KICAgICAgICAgICAgICAgIDxwYXRoIGQ9Ik0zNS4wMDc3MTgsODAgQzQyLjkwNjIwMDcsNzYuNDU0OTM1OCA0Ny41NjQ5MTY3LDcxLjU0MjI2NzEgNDguOTgzODY2LDY1LjI2MTk5MzkgQzUxLjExMjI4OTksNTUuODQxNTg0MiA0MS42NzcxNzk1LDQ5LjIxMjIyODQgMjUuNjIzOTg0Niw0OS4yMTIyMjg0IEMyNS40ODQ5Mjg5LDQ5LjEyNjg0NDggMjkuODI2MTI5Niw0My4yODM4MjQ4IDM4LjY0NzU4NjksMzEuNjgzMTY4MyBMNzIuODcxMjg3MSwzMi41NTQ0MjUgTDY1LjI4MDk3Myw2Ny42NzYzNDIxIEw1MS4xMTIyODk5LDc3LjM3NjE0NCBMMzUuMDA3NzE4LDgwIFoiIGlkPSJQYXRoLTIyIiBmaWxsPSIjMDAyODY4Ij48L3BhdGg+CiAgICAgICAgICAgICAgICA8cGF0aCBkPSJNMCwzNy43MzA0NDA1IEwyNy4xMTQ1MzcsMC4yNTcxMTE0MzYgQzYyLjM3MTUxMjMsLTEuOTkwNzE3MDEgODAsMTAuNTAwMzkyNyA4MCwzNy43MzA0NDA1IEM4MCw2NC45NjA0ODgyIDY0Ljc3NjUwMzgsNzkuMDUwMzQxNCAzNC4zMjk1MTEzLDgwIEM0Ny4wNTUzNDg5LDc3LjU2NzA4MDggNTMuNDE4MjY3Nyw3MC4zMTM2MTAzIDUzLjQxODI2NzcsNTguMjM5NTg4NSBDNTMuNDE4MjY3Nyw0MC4xMjg1NTU3IDM2LjMwMzk1NDQsMzcuNzMwNDQwNSAyNS4yMjc0MTcsMzcuNzMwNDQwNSBDMTcuODQzMDU4NiwzNy43MzA0NDA1IDkuNDMzOTE5NjYsMzcuNzMwNDQwNSAwLDM3LjczMDQ0MDUgWiIgaWQ9IlBhdGgtMTkiIGZpbGw9IiMzNzkzRUYiPjwvcGF0aD4KICAgICAgICAgICAgPC9nPgogICAgICAgIDwvZz4KICAgIDwvZz4KPC9zdmc+' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "colab": {
   "name": "load_data_from_ogbn_arxiv.ipynb",
   "provenance": [],
   "toc_visible": true,
   "collapsed_sections": [],
   "include_colab_link": true
  },
  "deepnote_notebook_id": "3d0de2b8-b983-4049-9473-027434fb26e8",
  "deepnote": {},
  "deepnote_execution_queue": []
 }
}